{"cells":[{"cell_type":"code","source":["from datetime import datetime\nfrom decimal import Decimal\nfrom typing import List\nfrom pyspark.sql.types import DateType, DecimalType, IntegerType, StructType, StructField, StringType, TimestampType\nfrom pyspark.sql import SparkSession\nimport json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d194ba20-3e08-4e23-92c9-c65ec138a3e0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if not any(mount.mountPoint == \"/mnt/azuremountcfgc\" for mount in dbutils.fs.mounts()):\n    dbutils.fs.mount(\n        source = \"wasbs://gccontainer@cfgcstorage.blob.core.windows.net\",\n        mount_point = \"/mnt/azuremountcfgc\",\n        extra_configs = {\"fs.azure.account.key.cfgcstorage.blob.core.windows.net\":\"yyHYfFxpI0AWxsOdFJH699cGYQh60CutcVcsrJfo5UMPixDJdcRTNSudo+Nfz9/lrMZTxyAjNiZO+AStaG7M1w==\"}\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8351a7c2-987c-47a5-b504-28ebd26ec131"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def get_dir_content(ls_path):\n  dir_paths = dbutils.fs.ls(ls_path)\n  subdir_paths = [get_dir_content(p.path) for p in dir_paths if p.isDir() and p.path != ls_path]\n  flat_subdir_paths = [p for subdir in subdir_paths for p in subdir]\n  return list(map(lambda p: p.path, dir_paths)) + flat_subdir_paths"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e394f04c-6534-4857-a977-f25b32aebe1d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def common_event(trade_dt: DateType, rec_type: StringType, symbol: StringType, exchange: StringType,\n                 event_tm: TimestampType, event_seq_nb: IntegerType, arrival_tm: TimestampType,\n                 trade_pr: DecimalType(30, 15), trade_size: IntegerType, bid_pr: DecimalType(30, 15),\n                 bid_size: IntegerType, ask_pr: DecimalType(30, 15), ask_size: IntegerType, partition: StringType,\n                 line: StringType):\n    \"\"\"Returns common event schema\n\n    Args:\n        ... field and data type for common schema\n        partition: partition key for trade quote or bad T,Q, or B\n        line: used to return bad line\n    Returns:\n        either the bad line or good record as list of values for each field\"\"\"\n\n    if partition == \"B\":\n        return line\n    else:\n        return [trade_dt, rec_type, symbol, exchange,\n                event_tm, event_seq_nb, arrival_tm,\n                trade_pr, trade_size, bid_pr, bid_size, ask_pr, ask_size, partition, line]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e26ec3c6-c190-4387-baa4-a29d69a41980"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def parse_csv(line: str):\n    \"\"\"CSV parser to be used in Spark transformation process\"\"\"\n    record_type_pos = 2\n    record = line.split(',')\n    try:\n        # logic to parse records\n        if record[record_type_pos] == 'T':\n            event = common_event(datetime.strptime(record[0], \"%Y-%m-%d\"), record[2], record[3], record[6],\n                                 datetime.strptime(record[4], '%Y-%m-%d %H:%M:%S.%f'), int(record[5]),\n                                 datetime.strptime(record[1], '%Y-%m-%d %H:%M:%S.%f'), Decimal(record[7]),\n                                 int(record[8]), None, None, None, None, 'T', None)\n            return event\n        elif record[record_type_pos] == 'Q':\n            event = common_event(datetime.strptime(record[0], \"%Y-%m-%d\"), record[2], record[3], record[6],\n                                 datetime.strptime(record[4], '%Y-%m-%d %H:%M:%S.%f'), int(record[5]),\n                                 datetime.strptime(record[1], '%Y-%m-%d %H:%M:%S.%f'), None, None, Decimal(record[7]),\n                                 int(record[8]), Decimal(record[9]), int(record[10]), 'Q', None)\n            return event\n    except Exception as e:\n        # save record to dummy event in bad partition\n        # fill in the fields as None or empty string\n        print(e)\n        return common_event(None, None, None, None, None, None, None, None, None, None, None, None, None, \"B\",line)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b902e1a7-1d94-41a7-882a-65b190da35dd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def parse_json(line: str):\n    record = json.loads(line)\n    record_type = record['event_type']\n    try:\n        # logic to parse records\n        if record_type == \"T\":\n            event = common_event(datetime.strptime(record[\"trade_dt\"], \"%Y-%m-%d\"), record[\"event_type\"],\n                                 record[\"symbol\"], record[\"exchange\"],\n                                 datetime.strptime(record[\"event_tm\"], '%Y-%m-%d %H:%M:%S.%f'),\n                                 int(record[\"event_seq_nb\"]),\n                                 datetime.strptime(record[\"file_tm\"], '%Y-%m-%d %H:%M:%S.%f'), Decimal(record[\"price\"]),\n                                 int(record[\"size\"]), None, None, None, None, \"T\", None)\n            return event\n        elif record_type == 'Q':\n            event = common_event(datetime.strptime(record[\"trade_dt\"], \"%Y-%m-%d\"), record[\"event_type\"],\n                                 record[\"symbol\"], record[\"exchange\"],\n                                 datetime.strptime(record[\"event_tm\"], '%Y-%m-%d %H:%M:%S.%f'),\n                                 int(record[\"event_seq_nb\"]),\n                                 datetime.strptime(record[\"file_tm\"], '%Y-%m-%d %H:%M:%S.%f'), None, None,\n                                 Decimal(record[\"bid_pr\"]), int(record[\"bid_size\"]), Decimal(record[\"ask_pr\"]),\n                                 int(record[\"ask_size\"]), \"Q\", None)\n            return event\n    except Exception as e:\n        print(e)\n        return common_event(None, None, None, None, None, None, None, None, None, None, None, None, None, \"B\", line)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b9b999f-9b02-4fd7-9376-7d716a790840"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def process_file(path, schem):\n    raw = spark.sparkContext.textFile(path)\n    if 'nyse' in path:\n        parsed = raw.map(lambda line: parse_csv(line))\n    else:\n        parsed = raw.map(lambda line: parse_json(line))\n    data = spark.createDataFrame(parsed, schema=schem)\n    return data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c6aa22e-4a9c-41ef-8669-aa516a70f52d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["schema = StructType().add(\"trade_dt\", DateType()).add(\"rec_type\", StringType()).add(\"symbol\", StringType())\\\n    .add(\"exchange\", StringType()).add(\"event_tm\", TimestampType()).add(\"event_seq_nb\", IntegerType())\\\n    .add(\"arrival_tm\", TimestampType()).add(\"trade_pr\", DecimalType()).add(\"trade_size\", IntegerType())\\\n    .add(\"bid_pr\", DecimalType()).add(\"bid_size\", IntegerType()).add(\"ask_pr\", DecimalType())\\\n    .add(\"ask_size\", IntegerType()).add(\"partition\", StringType()).add(\"line\", StringType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6da91c81-0ce4-4da1-a919-589fd8578ac5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["paths = [p for p in get_dir_content(\"/mnt/azuremountcfgc\") if '.txt' in p]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b16ff18b-0c63-48fc-88d4-5abd91999f6c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for path in paths:\n    df = process_file(path, schema)\n    trade_date = df.first()['trade_dt']\n    partition = df.first()['partition']\n    df.write.partitionBy(\"partition\").mode(\"append\").parquet(f\"/mnt/azuremountcfgc/output/{trade_date}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea43082f-eb09-4c72-8e65-153db97efff3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fcf3e5b2-dde2-4f1f-9455-34ba999de6bd"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"GuidedCapstoneFinal","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4497323250226901}},"nbformat":4,"nbformat_minor":0}
